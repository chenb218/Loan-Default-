---
title: "Final Ames Project, Barry Chen"
output:
  html_document:
    df_print: paged
---

```{r}
#loading libraries
library(tidymodels)
library(tidyverse)
library(janitor)
library(vip)
library(skimr)
library(tidyverse)
library(dials)
library(recipes)
library(parsnip)
library(yardstick)
library(rsample)
library(tune)
library(janitor)
library(patchwork)
library(solitude) # -- new package 
library(ggpubr)

```

```{r}
#Importing Data 

loan <- read_csv("loan_train.csv", na = c("NA","","-")) %>% 
  clean_names() %>% 
  mutate(int_rate = as.numeric(str_replace(int_rate,"%","")),
         revol_util = as.numeric(str_replace(revol_util,"%","")),
         empl_year = word(emp_length)) 
  

holdout <- read_csv("loan_holdout.csv") %>% 
  clean_names() %>% 
  mutate(int_rate = as.numeric(str_replace(int_rate,"%","")),
         revol_util = as.numeric(str_replace(revol_util,"%","")),
         empl_year = word(emp_length)) 
```
#Exploring Numerics
```{r}
#Exploring the dataset of Numerics
skim(loan)


  ggplot(loan,aes(x = int_rate , y = loan_status, fill = loan_status)) +
  geom_boxplot(color = "cornflowerblue", alpha = 0.75) +
  labs(title = 'Interest Rate ')+
  labs(title = 'Interest Rate Box Plot', x = 'Interest Rate' , y = 'Loan Status')  
  
   ggplot(loan,aes(x = revol_util , y = loan_status)) +
  geom_boxplot(color = "cornflowerblue", alpha = 0.75) +
  labs(title = 'revol_util Box plot ')
   
     ggplot(loan,aes(x = total_acc , y = loan_status)) +
  geom_boxplot(color = "cornflowerblue", alpha = 0.75) +
  labs(title = 'revol_util Box plot ')
  
  ggplot(loan,aes(x = delinq_2yrs)) +
  geom_histogram(color = "cornflowerblue", alpha = 0.75) +
  labs(title = 'delinq_2yrs Histogram ')
  
  ggplot(loan,aes(x = delinq_2yrs)) +
  geom_boxplot(color = "cornflowerblue", alpha = 0.75) +
  labs(title = 'delinq_2yrs Boxplot')

#Correlation Matrix 

  loan_corr <- loan %>% 
  dplyr::select_if(is.numeric) %>% 
    subset(select= -c(tax_liens, pub_rec_bankruptcies , delinq_amnt, acc_now_delinq, chargeoff_within_12_mths, acc_now_delinq, policy_code, collections_12_mths_ex_med)) %>% 
  na.omit() 
  
skim(loan_corr)
  
cormat <- cor(loan_corr)
round(cormat, 2) 
corrplot(cormat)



#ggtexttable(donor_summary, rows = NULL, 
                        #theme = ttheme("mOrange"))
```
#Categorical Exploration
```{r}
skim(loan)
loan %>% 
  dplyr::select(term) %>% 
  na.omit() %>% 
  count(term) %>% 
  mutate(pct = n/sum(n)) %>% 
  ggplot(aes(x= term,y = n, fill = pct, label = round(pct,2))) +
  geom_col( alpha = 0.75) +
   geom_text(aes(label = round(pct,2)) , vjust = 2.5, colour = "white") +
  labs(title = 'Term Count', x = 'Term' , y = 'Count', legend = 'Term')  

loan %>% 
  ggplot(aes(x= pymnt_plan)) +
  geom_bar(fill = "cornflowerblue", alpha = 0.75) +
  labs(title = 'Term Count', x = 'Term' , y = 'Count')  

loan %>% 
  ggplot(aes(x= home_ownership )) +
  geom_bar(fill = "cornflowerblue", alpha = 0.75) +
  labs(title = 'Term Count', x = 'Term' , y = 'Count')  

loan %>% 
  ggplot(aes(x= verification_status )) +
  geom_bar(fill = "cornflowerblue", alpha = 0.75) +
  labs(title = 'Verification Status Count', x = 'Verification Status' , y = 'Count')

loan %>% 
  dplyr::select(verification_status) %>% 
  na.omit() %>% 
  count(verification_status) %>% 
  mutate(pct = n/sum(n)) %>% 
  ggplot(aes(x= verification_status,y = n, fill = pct, label = round(pct,2))) +
  geom_col( alpha = 0.75) +
    geom_text(aes(label = round(pct,2)) , vjust = 2.5, colour = "white") +
  labs(title = 'Verification Status Count', x = 'Verification Status' , y = 'Count')  

  

  
```


#Exploring Target Variable
```{r}

#explore target 
loan_summary <- loan %>%
  count(loan_status) %>%
  mutate(pct = n/sum(n))

loan_summary %>%
  ggplot(aes(x=factor(loan_status),y=pct)) +
  geom_col(fill= 'cornflower blue')  + 
  geom_text(aes(label = round(pct,2)) , vjust = 2.5, colour = "white") + 
  labs(title="Loan Defaults ", x="Loan Status", y="PCT") #85% of the data are current - 15% are default

loan %>%
  group_by(addr_state) %>% 
  count(loan_status) %>% 
  na.omit() %>% 
  slice_max(order_by= n, n= 10 ) %>% 
  ggplot(aes(x = reorder(addr_state,-n),y = n,  fill = loan_status)) + geom_col()+
  labs(x = 'State', y = 'Count', legend = 'Loan Status') +
  ggtitle('Count of Default vs. Current by State')  + theme(
  axis.text.x = element_text(angle = 90) 
)
```




#Overall Prep
```{r}
#changing character variables to factors
loan_prep <- loan %>% 
  mutate(loan_status = as.factor(loan_status) ) %>%
   mutate_if(is.character, factor) 
loan_prep %>% head()

skim(loan_prep)
```

#Isolation Forest 
```{r}
# make a recipe 
iso_recipe <- recipe(~ annual_inc + 
                       fico_range_high +
                       open_acc + 
                       installment + 
                       funded_amnt + 	out_prncp + last_pymnt_amnt
                       , loan) %>% 
  step_impute_mean(all_predictors()) %>% 
  prep()


# bake it
iso_prep <- bake(iso_recipe, loan)

# init a isoforest 
iso_forest <- isolationForest$new(
  sample_size = 2048,
  num_trees = 100,
  max_depth = 12)
# fit
iso_forest$fit(iso_prep)
# predict
pred_loan <- iso_forest$predict(iso_prep)
#sumarize
pred_loan %>%
  summarise(n=n(),
            min = min(average_depth),
            max = max(average_depth),
            mean = mean(average_depth),
            min_score =  min(anomaly_score),
            max_score = max(anomaly_score),
            mean_score= mean(anomaly_score),
    
  )
# pl0t
pred_loan %>%
  ggplot(aes(average_depth)) +
  geom_histogram(bins=20) + 
  geom_vline(xintercept = 10, linetype="dotted", 
                color = "blue", size=1.5) + 
  labs(title="Isolation Forest Average Tree Depth")
# plot
pred_loan %>%
  ggplot(aes(anomaly_score)) +
  geom_histogram(bins=20) + 
  geom_vline(xintercept = 0.7, linetype="dotted", 
                color = "blue", size=1.5) + 
  labs(title="Isolation Forest Anomaly Score Above 0.7")

# Who is anomalous?
bind_cols(pred_loan, loan) %>% 
  filter(anomaly_score>0.7) 

# make a surrogate model 
synth_loan <- bind_cols(pred_loan, iso_prep) %>%
  mutate(synthetic_target = as.factor(
           if_else(anomaly_score >= 0.7,"default","current"))
         ) %>%
  select(-average_depth, -anomaly_score, -id)

synth_loan
# fit a model 
fmla <- as.formula(paste("synthetic_target ~ ", paste(synth_loan %>% colnames(), collapse= "+")))

outlier_tree <- decision_tree(min_n=2, tree_depth=3, cost_complexity = .01) %>%
  set_mode("classification") %>%
  set_engine("rpart") %>%
  fit(fmla, data=synth_loan)

outlier_tree$fit

synth_loan %>% 
  count(synthetic_target)

```

# Global Anomaly Rules 

eyeball what makes an anomaly

```{r}
library(rpart.plot)
library(rpart)
anomaly_rules <- rpart.rules(outlier_tree$fit,roundint=FALSE, extra = 4, cover = TRUE, clip.facs = TRUE) %>% clean_names() %>%
  #filter(anomaly=="Anomaly") %>%
  mutate(rule = "IF") 


rule_cols <- anomaly_rules %>% select(starts_with("x_")) %>% colnames()

for (col in rule_cols){
anomaly_rules <- anomaly_rules %>%
    mutate(rule = paste(rule, !!as.name(col)))
}

anomaly_rules %>%
  as.data.frame() %>%
  filter(synthetic_target != "current") %>%
  mutate(rule = paste(rule, " THEN ", synthetic_target )) %>%
  mutate(rule = paste(rule," coverage ", cover)) %>%
  select( rule)

anomaly_rules %>%
  as.data.frame() %>%
  filter(synthetic_target == "current") %>%
  mutate(rule = paste(rule, " THEN ", synthetic_target )) %>%
  mutate(rule = paste(rule," coverage ", cover)) %>%
  select( rule)



```

## explain 5 anomalies 

```{r}

# Who is anomalous?
pred_loan <- iso_forest$predict(iso_prep)
pred_loan <- bind_cols(pred_loan, iso_prep) %>%
  mutate(synthetic_target = as.factor(
           if_else(anomaly_score >= 0.7,"default","current"))
         ) 

local_explainer <- function(ID){
  
  fmla <- as.formula(paste("anomaly ~ ", paste(iso_prep %>% colnames(), collapse= "+")))
  
  pred_loan %>%
    mutate(anomaly= as.factor(if_else(id==ID, "Anomaly", "Normal"))) -> local_df
  
  local_tree <-  decision_tree(mode="classification",
                              tree_depth = 3,
                              min_n = 1,
                              cost_complexity=0) %>%
                set_engine("rpart") %>%
                    fit(fmla,local_df )
  
  local_tree$fit
  
  #rpart.rules(local_tree$fit, extra = 4, cover = TRUE, clip.facs = TRUE)
  rpart.plot(local_tree$fit, roundint=FALSE, extra=3) %>% print()
  
  anomaly_rules <- rpart.rules(local_tree$fit, extra = 4, cover = TRUE, clip.facs = TRUE) %>% clean_names() %>%
    filter(anomaly=="Anomaly") %>%
    mutate(rule = "IF") 
  
  
  rule_cols <- anomaly_rules %>% select(starts_with("x_")) %>% colnames()
  
  for (col in rule_cols){
  anomaly_rules <- anomaly_rules %>%
      mutate(rule = paste(rule, !!as.name(col)))
  }
  
  as.data.frame(anomaly_rules) %>%
    select(rule, cover) %>%
    print()
}

pred_loan %>%
  slice_max(order_by=anomaly_score,n=10) %>%
  pull(id) -> anomaly_vect

for (anomaly_id in anomaly_vect){
  local_explainer(anomaly_id)
}

pred_loan %>%
  ggplot(aes(annual_inc
             ))+geom_boxplot()





```

```{r}



```

## explain 5 anomalies 

```{r}


```
#LGM Partition the Data
```{r}
#Partition the Data
set.seed(123)
loan_split <- initial_split(loan_prep, prop = 0.7, strata = loan_status)
train <- training(loan_split)
test  <- testing(loan_split)

sprintf("Train PCT : %1.2f%%", nrow(train)/ nrow(loan_prep) * 100)
sprintf("Test  PCT : %1.2f%%", nrow(test)/ nrow(loan_prep) * 100)
```
#Logistic Recipe
```{r}
#Logistic Recipe
lgm_recipe <- recipe(loan_status ~. ,
                     data=train) %>%
  step_rm(emp_title, url, desc, title, zip_code, earliest_cr_line, revol_util, last_pymnt_d, member_id, id, addr_state, next_pymnt_d,  application_type,  issue_d, collections_12_mths_ex_med, policy_code, chargeoff_within_12_mths,delinq_2yrs, mths_since_last_delinq, 	mths_since_last_record, pub_rec_bankruptcies, sub_grade,dti, funded_amnt_inv, acc_now_delinq, tax_liens, emp_length, home_ownership, verification_status, purpose, delinq_amnt,out_prncp_inv, fico_range_high, total_acc) %>% 
  step_impute_median(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) 


#Bake 
bake_train <- bake(lgm_recipe %>% prep(), train,  composition = "tibble") %>% head()
```
#LGM Define the Model 
```{r}
#Define the Model 

logistic_model <- logistic_reg() %>%
  set_mode("classification") %>%
  set_engine("glm")

logistic_workflow <- workflow() %>%
  add_recipe(lgm_recipe) %>%
  add_model(logistic_model) %>%
  fit(train)

```
#LGM Evaluating
```{r}
#Evaluating
options(yardstick.event_first = FALSE)
 predict_and_eval <- function(workflow_fit){
  # 1. Make Predictions
scored_train <- predict(workflow_fit, train, type="prob") %>%
      mutate(part = 'train') %>% 
    bind_cols(predict(workflow_fit, train, type="class")) %>%
    bind_cols(.,train) 

scored_test <- predict(workflow_fit, test, type="prob") %>%
  mutate(part = 'test') %>% 
    bind_cols(predict(workflow_fit, test, type="class")) %>%
    bind_cols(.,test)


#Metrics: Train and Test 
  auc<- scored_train %>% 
    metrics(truth = loan_status, 
            predicted = .pred_default, 
            estimate = .pred_class) %>%
    mutate(part="training") %>%
    bind_rows( scored_test %>% 
                  metrics(truth = loan_status, 
            predicted = .pred_default, 
            estimate = .pred_class) %>%
                 mutate(part="testing") ) %>%
    filter(.metric %in% c('accuracy','mn_log_loss','roc_auc')) %>%
    pivot_wider(names_from = .metric, values_from=.estimate) 
  
  print(auc)
  
 roc_chart <- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  roc_curve(truth=loan_status, predicted=.pred_default) %>% 
  autoplot() +
  geom_vline(xintercept = 0.1,    
             color = "red",
             linetype = "longdash") +
   geom_vline(xintercept = 0.20,    
             color = "black",
             linetype = "longdash") +
   labs(title = 'ROC For Logistic Regression', x = "FPR(1 - specificity)", y = "TPR(recall)") 
 
 print(roc_chart)
  
 con_train <-  scored_train %>%
  conf_mat(
  truth = loan_status,
  estimate = .pred_class,
  dnn = c("Prediction", "Truth")
) %>%
  autoplot(type = "heatmap") + 
  labs(title="Training Confusion Matrix")
 
 print(con_train)

 con_test <-  scored_test %>%
  conf_mat(
  truth = loan_status,
  estimate = .pred_class,
  dnn = c("Prediction", "Truth")
) %>%
  autoplot(type = "heatmap") + 
  labs(title="Testing Confusion Matrix")
  
   print(con_test)
   
    precision<- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  precision(loan_status, .pred_class) 
      
    
    print(precision)
    
recall <-bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  recall(loan_status, .pred_class) 

print(recall)

f1<- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  f_meas(loan_status, .pred_class) 

print(f1)

 score_dist <-scored_test %>%
  ggplot(aes(.pred_default,fill=loan_status)) +
  geom_histogram(bins=50) +
  geom_vline(aes(xintercept=.25, color="red")) +
  geom_vline(aes(xintercept=.5, color="green")) +
  geom_vline(aes(xintercept=.75, color="blue")) +
  labs(title = 'Logistic Regression Precision Recall Threshold') 

print(score_dist)

 }
 
 predict_and_eval(logistic_workflow)
 
```
 
#LGM VIP and Partial Dependency Plot
```{r}
#VIP

logistic_workflow %>%
 pull_workflow_fit() %>%
  tidy() %>%
  mutate_if(is.numeric,round,2)

logistic_workflow %>%
  pull_workflow_fit() %>%
  vip(5) + 
    labs(title ="LGM VIP") 
#Partial Dependency 
library(DALEX)
library(DALEXtra)

#Create explainer: ###last_pymnt_amnt### 
lgm_explainer <- explain_tidymodels(
  logistic_workflow,
  data = train ,
  y = train$loan_default ,
  verbose = TRUE
)

#Create profile for single variable 
profile_last_pymnt_amnt <- model_profile(
  lgm_explainer,
  variables = c("last_pymnt_amnt")
)

#Plotting
as_tibble(profile_last_pymnt_amnt$agr_profiles) %>%
  mutate(profile_last_pymnt_amnt = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_last_pymnt_amnt, y=avg_prediction_impact)) + geom_smooth() + geom_point(aes(fill = profile_last_pymnt_amnt))+ theme_economist() + theme(legend.position="false", strip.background = element_blank(), strip.text.x = element_blank()) +
  labs(
    x = "Variable: Last Payment Amount",
     y = " Average prediction Impact ",
    color = NULL,
    title = "Partial dependence plot LPA",
    subtitle = "How does Last Payment Amount Impact Predictions (on average)"
  ) 



#Create profile for single variable  ###totalreclatefee
profile_total_rec_late_fee <- model_profile(
  lgm_explainer,
  variables = c("total_rec_late_fee")
)

#Plotting
as_tibble(profile_total_rec_late_fee$agr_profiles) %>%
  mutate(profile_total_rec_late_fee = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_total_rec_late_fee, y=avg_prediction_impact)) + geom_smooth() + geom_point(aes(fill = profile_total_rec_late_fee))+ theme_economist() + theme(legend.position="false", strip.background = element_blank(), strip.text.x = element_blank()) +
  labs(
    x = "Variable: Total Rec Late Fee",
     y = " Average prediction Impact ",
    color = NULL,
    title = "Partial Dependence Plot: Total Rec Late Fee",
    subtitle = "How does Total Rec Late Fee impact predictions (on average)"
  ) 

#out_pncrp
profile_out_prncp <- model_profile(
  lgm_explainer,
  variables = c("out_prncp")
)

#Plotting
as_tibble(profile_out_prncp$agr_profiles) %>%
  mutate(profile_out_prncp = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_out_prncp, y=avg_prediction_impact)) + geom_smooth() + geom_point(aes(fill = profile_out_prncp))+ theme_economist() + theme(legend.position="false", strip.background = element_blank(), strip.text.x = element_blank()) +
  labs(
    x = "Variable: Remaining Principal",
     y = " Average Prediction Impact ",
    color = NULL,
    title = "Partial Dependence Plot of Outstanding Principal",
    subtitle = "How does Total Remaining Outstanding Principal impact predictions (on average)"
  ) 

#inq_last_6mmonths 
profile_inq_last_6mths <- model_profile(
  lgm_explainer,
  variables = c("inq_last_6mths")
)

#Plotting
as_tibble(profile_inq_last_6mths$agr_profiles) %>%
  mutate(profile_inq_last_6mths = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_inq_last_6mths, y=avg_prediction_impact)) + geom_smooth() + geom_point(aes(fill = profile_inq_last_6mths))+ theme_economist() + theme(legend.position="false", strip.background = element_blank(), strip.text.x = element_blank()) +
  labs(
    x = "Variable: # of Inquiries in Last 6 Months",
     y = " Average prediction Impact ",
    color = NULL,
    title = "Partial Dependence Plot: # of Inquiries in Last 6 Months",
    subtitle = "How does # of Inquiries in Last 6 Months impact predictions (on average)"
  ) 

#annual_inc
profile_annual_inc <- model_profile(
  lgm_explainer,
  variables = c("annual_inc")
)

#Plotting
as_tibble(profile_annual_inc$agr_profiles) %>%
  mutate(profile_annual_inc = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_annual_inc, y=avg_prediction_impact)) + geom_smooth() + geom_point(aes(fill = profile_annual_inc))+ theme_economist() + theme(legend.position="false", strip.background = element_blank(), strip.text.x = element_blank()) +
  labs(
    x = "Variable: Annual Income",
     y = " Average Prediction Impact ",
    color = NULL,
    title = "Partial dependence plot: Annual Income",
    subtitle = "How does Annual Income impact predictions (on average)"
  ) 


loan
```

#LGM Operating Table 
```{r}

predict_and_operate_lgm <- function(workflow_fit){

scored_train <- predict(workflow_fit, train, type="prob") %>%
      mutate(part = 'train') %>% 
    bind_cols(.,train) 

scored_test <- predict(workflow_fit, test, type="prob") %>%
  mutate(part = 'test') %>%
    bind_cols(.,test)


scored_test %>%
  roc_curve(loan_status, .pred_default)  %>%
  mutate(
    fpr = round((1 - specificity), 2),
    tpr = round(sensitivity, 3),
    score_threshold =  round(.threshold, 3)
  ) %>%
  group_by(fpr) %>%
  summarise(threshold = round(mean(score_threshold),3),
            tpr = mean(tpr)) %>%
  filter(fpr <= 0.25)
}

predict_and_operate_lgm(logistic_workflow)
```
#LGM Loan Savings
```{r}
predict_and_save <- function(workflow_fit){
  scored_train <- predict(workflow_fit, train, type="prob") %>%
    bind_cols(predict(workflow_fit, train, type="class")) %>% 
     mutate(part = 'train', .pred_class = as.factor(if_else(.pred_default >=.275,'default','current'))) %>% 
    bind_cols(.,train) 

scored_test <- predict(workflow_fit, test, type="prob") %>%
   bind_cols(predict(workflow_fit, test, type="class")) %>%
  mutate(part = 'test', .pred_class = as.factor(if_else(.pred_default >=.275,'default','current'))) %>% 
    bind_cols(.,test)

#Metrics: Train and Test 
  auc<- scored_train %>% 
    metrics(truth = loan_status, 
            predicted = .pred_default, 
            estimate = .pred_class) %>%
    mutate(part="training") %>%
    bind_rows( scored_test %>% 
                  metrics(truth = loan_status, 
            predicted = .pred_default, 
            estimate = .pred_class) %>%
                 mutate(part="testing") ) %>%
    filter(.metric %in% c('accuracy','mn_log_loss','roc_auc')) %>%
    pivot_wider(names_from = .metric, values_from=.estimate) 
  
  print(auc)
  
 roc_chart <- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  roc_curve(truth=loan_status, predicted=.pred_default) %>% 
  autoplot() +
  geom_vline(xintercept = 0.04,    
             color = "red",
             linetype = "longdash") +
   geom_vline(xintercept = 0.20,    
             color = "black",
             linetype = "longdash") +
   labs(title = 'ROC For Logistic Regression', x = "FPR(1 - specificity)", y = "TPR(recall)") 
 
 print(roc_chart)
  
 con_train <-  scored_train %>%
  conf_mat(
  truth = loan_status,
  estimate = .pred_class,
  dnn = c("Prediction", "Truth")
) %>%
  autoplot(type = "heatmap") + 
  labs(title="Training Confusion Matrix")
 
 print(con_train)

 con_test <-  scored_test %>%
  conf_mat(
  truth = loan_status,
  estimate = .pred_class,
  dnn = c("Prediction", "Truth")
) %>%
  autoplot(type = "heatmap") + 
  labs(title="Testing Confusion Matrix")
  
   print(con_test)
   
    precision<- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  precision(loan_status, .pred_class) 
      
    
    print(precision)
    
recall <-bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  recall(loan_status, .pred_class) 

print(recall)

f1<- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  f_meas(loan_status, .pred_class) 

print(f1)

 score_dist <-scored_test %>%
  ggplot(aes(.pred_default,fill=loan_status)) +
  geom_histogram(bins=50) +
  geom_vline(aes(xintercept=.5, color="red")) +
  geom_vline(aes(xintercept=.275, color="green")) +
  geom_vline(aes(xintercept=.7, color="blue")) +
  labs(title = 'Logistic Regression') 

print(score_dist)

}

predict_and_save(logistic_workflow)
```


#Random Forest Prepping
```{r}
#Random Forest 
rf_prep <- loan %>% 
  mutate_if(is.character, factor)

#Partition
set.seed(4)

rf_split <- initial_split(rf_prep, prop = 0.7, strata = loan_status)
rf_train <- training(rf_split)
rf_test  <- testing(rf_split)

sprintf("Train PCT : %1.2f%%", nrow(rf_train)/ nrow(rf_prep) * 100)
sprintf("Test  PCT : %1.2f%%", nrow(rf_test)/ nrow(rf_prep) * 100)
```

#RF Recipe
```{r}
#RF Recipe
rf_recipe <- recipe(loan_status ~. , data=rf_train) %>%
  step_rm(emp_title, url, desc, title, zip_code, earliest_cr_line, revol_util, last_pymnt_d, member_id, id, addr_state, next_pymnt_d,  application_type,  issue_d, collections_12_mths_ex_med, policy_code, chargeoff_within_12_mths,delinq_2yrs, mths_since_last_delinq, 	mths_since_last_record, pub_rec_bankruptcies, sub_grade,dti, funded_amnt_inv, acc_now_delinq, tax_liens, emp_length, home_ownership, verification_status, purpose, delinq_amnt,out_prncp_inv, fico_range_high, total_acc) %>%   
  step_impute_median(all_numeric_predictors()) %>%
  step_novel(all_nominal_predictors()) %>% 
  step_unknown(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) 

rf_bake_train <- bake(rf_recipe %>% prep(), rf_train,  composition = "tibble") 
```
##rf_model <- rand_forest(trees = tune(), min_n = tune(), mtry = tune()) %>%
   set_mode("classification") %>%
   set_engine("ranger", importance = 'permutation')
#RF Define Model AND EVALUATION 
```{r}
#Define Model 
rf_model <- rand_forest(trees = 200, min_n = 10) %>%
   set_mode("classification") %>%
   set_engine("ranger", importance = 'impurity')

#RF Workflow
rf_workflow <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_model) %>% 
  fit(rf_train)

predict(rf_workflow, rf_train, type = "prob") %>%
  bind_cols(predict(rf_workflow, rf_train, type = "class")) %>%
  mutate(part = "train") %>%
  bind_cols(., rf_train) -> rf_scored_train

# -- score testing

predict(rf_workflow, rf_test, type = "prob") %>%
  bind_cols(predict(rf_workflow,  rf_test, type = "class")) %>%
  mutate(part = "testing") %>%
  bind_cols(., rf_test) -> rf_scored_test

bind_rows (rf_scored_train, rf_scored_test)  %>%
  group_by(part) %>% 
  metrics(loan_status, .pred_default, estimate = .pred_class) %>%
  filter(.metric %in% c('accuracy', 'roc_auc', 'mn_log_loss')) %>%
  pivot_wider(names_from = .metric, values_from = .estimate) 

  bind_rows(rf_scored_train, rf_scored_test) %>%
  group_by(part) %>%
  precision(loan_status, .pred_class)

bind_rows(rf_scored_train, rf_scored_test) %>%
  group_by(part) %>%
  recall(loan_status, .pred_class) 

bind_rows(rf_scored_train, rf_scored_test) %>%
  group_by(part) %>%
  f_meas(loan_status, .pred_class) 


rf_workflow %>% 
  extract_fit_parsnip() %>%
  vi()

#Confusion Matrix
  rf_scored_train %>%
  conf_mat(
  truth = loan_status,
  estimate = .pred_class,
  dnn = c("Prediction", "Truth")
) %>%
  autoplot(type = "heatmap") + 
  labs(title="Training Confusion Matrix")

rf_scored_test %>%
  conf_mat(
  truth = loan_status,
  estimate = .pred_class,
  dnn = c("Prediction", "Truth")
) %>%
  autoplot(type = "heatmap") + 
  labs(title="Testing Confusion Matrix")

```

#RF Operating Range ORIGINAL
```{r}
predict_and_operate_rf <- function(workflow_fit){
  scored_train <- predict(workflow_fit, rf_train, type="prob") %>%
    bind_cols(predict(workflow_fit, rf_train, type="class")) %>%
    bind_cols(.,rf_train) 
  
  scored_test <- predict(workflow_fit, rf_test, type="prob") %>%
    bind_cols(predict(workflow_fit, rf_test, type="class")) %>%
    bind_cols(.,rf_test)

scored_test %>%
  roc_curve(loan_status, .pred_default)  %>%
  mutate(
    fpr = round((1 - specificity), 2),
    tpr = round(sensitivity, 3),
    score_threshold =  round(.threshold, 3)
  ) %>%
  group_by(fpr) %>%
  summarise(threshold = round(mean(score_threshold),3),
            tpr = mean(tpr)) %>%
  filter(fpr <= 0.1)
}

predict_and_operate_rf(rf_workflow)
```


#RF Tuning
```{r}
kfold_splits <- vfold_cv(rf_train, v=5)

rf_random_grid <- grid_random(trees(c(280,900)),
                         min_n(c(40,100)),
                          size = 20)
library(themis)      # over / under sampling methods 
library(doParallel)
library(parallel)

rf_model_tune <- rand_forest(trees = tune(), min_n = tune()) %>%
   set_mode("classification") %>%
   set_engine("ranger", importance = 'impurity')

rf_workflow_tune <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_model_tune)

all_cores <- detectCores(logical = TRUE)
sprintf("# of Logical Cores: %d", all_cores)
cl <- makeCluster(all_cores)
registerDoParallel(cl)

rf_tuning_results_random <- rf_workflow_tune %>% 
  tune_grid(
    resamples = kfold_splits,
    grid = rf_random_grid,
    control = control_resamples(save_pred = TRUE, verbose = TRUE)
    )
rf_tuning_results_random

#visualize evaluation
rf_tuning_results_random %>% 
  collect_metrics() %>%
  mutate_if(is.numeric, round,3) %>% 
  pivot_wider(names_from = .metric, values_from=c(mean, std_err))
# min_n
rf_tuning_results_random %>%
  collect_metrics()  %>%
  mutate_if(is.numeric, round,3) %>%
  ggplot(aes(min_n, mean, )) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  labs(title="impact of min_n = ")
#trees
rf_tuning_results_random %>%
  collect_metrics()  %>%
  mutate_if(is.numeric, round,3) %>%
  ggplot(aes(trees, mean, )) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  labs(title="impact of trees = ")

```
#RF TUNING Evaluation
```{r}
#Evaluation

highest_rf_roc <- rf_tuning_results_random %>%
  select_best("roc_auc")


rf_workflow_tune <- finalize_workflow(
  rf_workflow_tune, highest_rf_roc
) %>% 
  fit(rf_train)

rf_workflow_tune %>% 
  extract_fit_parsnip() %>%
  vi()

#Eval Tuned 

predict(rf_workflow_tune, rf_train, type = "prob") %>%
  bind_cols(predict(rf_workflow_tune, rf_train, type = "class")) %>%
  mutate(part = "train") %>%
  bind_cols(., rf_train) -> rf_scored_train_tune


predict(rf_workflow_tune, rf_test, type = "prob") %>%
  bind_cols(predict(rf_workflow_tune,  rf_test, type = "class")) %>%
  mutate(part = "testing") %>%
  bind_cols(., rf_test) -> rf_scored_test_tune

bind_rows (rf_scored_train_tune, rf_scored_test_tune)  %>%
  group_by(part) %>%
  metrics(loan_status, .pred_default, estimate = .pred_class) %>%
  filter(.metric %in% c('accuracy', 'roc_auc', 'mn_log_loss')) %>%
  pivot_wider(names_from = .metric, values_from = .estimate)


```


#RF TUNED Precision, Accuracy, F1
```{r}

  bind_rows(rf_scored_train_tune,rf_scored_test_tune) %>%
  group_by(part) %>%
  precision(loan_status, .pred_class)

bind_rows(rf_scored_train_tune,rf_scored_test_tune) %>%
  group_by(part) %>%
  recall(loan_status, .pred_class) 

bind_rows(rf_scored_train_tune,rf_scored_test_tune) %>%
  group_by(part) %>%
  f_meas(loan_status, .pred_class) 
```

#Nerual Network prepping data
```{r}
nn_prep <- loan %>% 
  mutate(loan_status = as.factor(loan_status))


```
#NN Partition
```{r}
set.seed(12345)
nn_split <- initial_split(nn_prep, loan_status, prop = 0.70)
nn_train <- training(nn_split) 
nn_test  <-  testing(nn_split)

sprintf("Train PCT : %1.2f%%", nrow(nn_train)/ nrow(nn_prep) * 100)
sprintf("Test  PCT : %1.2f%%", nrow(nn_test)/ nrow(nn_prep) * 100)
```
#NN K-fold cross- validation
```{r}
nn_kfold_splits <- vfold_cv(nn_train, v=5)
```
#NN Formula
```{r}
#Formula

nn_recipe <-
  recipe(loan_status ~. , data = nn_train) %>%
  step_rm(emp_title, url, desc, title, zip_code, earliest_cr_line, revol_util, last_pymnt_d, member_id, id, addr_state, next_pymnt_d,  application_type,  issue_d, collections_12_mths_ex_med, policy_code, chargeoff_within_12_mths, pymnt_plan, 	delinq_2yrs, mths_since_last_delinq, 	mths_since_last_record, pub_rec_bankruptcies, sub_grade,dti, funded_amnt, funded_amnt_inv, acc_now_delinq, tax_liens, emp_length, home_ownership, verification_status, installment, purpose, delinq_amnt,out_prncp_inv, fico_range_high, grade) %>% 
  step_unknown(all_nominal_predictors()) %>%
  step_impute_median(all_numeric_predictors()) %>% # missing values numeric 
  step_normalize(all_numeric_predictors())  %>%
  step_dummy(all_nominal_predictors(), one_hot=TRUE)
  
#Check Recipe
bake(nn_recipe %>% prep(),nn_train)-> nn_bake_train

```

#NN Define Tuning
```{r}
#Tuning

nn_model_tuned <- mlp(hidden_units = tune(),
                 penalty=tune(),
  epochs = tune(),
  ) %>%
  set_engine("nnet") %>%
  set_mode("classification") 

nn_workflow_tuned <-workflow() %>%
  add_recipe(nn_recipe) %>%
  add_model(nn_model_tuned) 

nn_search_res <- nn_workflow_tuned %>% 
  tune_bayes(
    resamples = nn_kfold_splits,
    # Generate five at semi-random to start
    initial = 40,
    iter = 50, 
    # How to measure performance?
    metrics = metric_set(roc_auc),
    control = control_bayes(no_improve =5, verbose = TRUE)
  )
```

#NN Tuning Fit 
```{r}
#best find
nn_search_res %>%
  collect_metrics() 
#Tuning Fit 
best_auc <- nn_search_res %>%
  select_best("roc_auc")

best_auc

nn_workflow_tuned <- finalize_workflow(
  nn_workflow_tuned, best_auc
) %>% 
  fit(nn_train)
```

#NN Evaluating Final Fit
```{r}

options(yardstick.event_first = FALSE)
#Evaluating Final Fit
eval_funk <- function(workflow_fit){
  # 1. Make Predictions
scored_train <- predict(workflow_fit, nn_train, type="prob") %>%
      mutate(part = 'train') %>% 
    bind_cols(predict(workflow_fit, nn_train, type="class")) %>%
    bind_cols(.,nn_train) 

scored_test <- predict(workflow_fit, nn_test, type="prob") %>%
  mutate(part = 'test') %>% 
    bind_cols(predict(workflow_fit, nn_test, type="class")) %>%
    bind_cols(.,nn_test)



 auc<- scored_train %>% 
    metrics(truth = loan_status, 
            predicted = .pred_default, 
            estimate = .pred_class) %>%
    mutate(part="training") %>%
    bind_rows( scored_test %>% 
                  metrics(truth = loan_status, 
            predicted = .pred_default, 
            estimate = .pred_class) %>%
                 mutate(part="testing") ) %>%
    filter(.metric %in% c('accuracy','mn_log_loss','roc_auc')) %>%
    pivot_wider(names_from = .metric, values_from=.estimate) 
  
  print(auc)
  
 con_train <-  scored_train %>%
  conf_mat(
  truth = loan_status,
  estimate = .pred_class,
  dnn = c("Prediction", "Truth")
) %>%
  autoplot(type = "heatmap") + 
  labs(title="Training Confusion Matrix")
 
 print(con_train)

 con_test <-  scored_test %>%
  conf_mat(
  truth = loan_status,
  estimate = .pred_class,
  dnn = c("Prediction", "Truth")
) %>%
  autoplot(type = "heatmap") + 
  labs(title="Testing Confusion Matrix")
  
   print(con_test)
   
    precision<- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  precision(loan_status, .pred_class) 
      
    
    print(precision)
    
recall <-bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  recall(loan_status, .pred_class) 

print(recall)

f1<- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  f_meas(loan_status, .pred_class) 

print(f1)

score_dist <-scored_test %>%
  ggplot(aes(.pred_default,fill=loan_status)) +
  geom_histogram(bins=50) +
  geom_vline(aes(xintercept=.25, color="red")) +
  geom_vline(aes(xintercept=.5, color="green")) +
  geom_vline(aes(xintercept=.75, color="blue")) +
  labs(title = 'Neural Network Precision Recall Threshold') 

print(score_dist)

roc_chart <- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  roc_curve(truth=loan_status, predicted=.pred_default) %>% 
  autoplot() +
   geom_vline(xintercept = 0.20,    
             color = "black",
             linetype = "longdash") +
   labs(title = 'ROC For Neural Network', x = "FPR(1 - specificity)", y = "TPR(recall)",
      ) 
 
 print(roc_chart)
 
vip<-  nn_workflow_tuned %>% 
  extract_fit_parsnip() %>%
  vi()

print(vip)

}

eval_funk(nn_workflow_tuned)
```
#NN Operating Range 
```{r}
predict_and_operate_nn <- function(workflow_fit){
  scored_train <- predict(workflow_fit, nn_train, type="prob") %>%
    bind_cols(predict(workflow_fit, nn_train, type="class")) %>%
    bind_cols(.,nn_train) 
  
  scored_test <- predict(workflow_fit, nn_test, type="prob") %>%
    bind_cols(predict(workflow_fit, nn_test, type="class")) %>%
    bind_cols(.,nn_test)

scored_test %>%
  roc_curve(loan_status, .pred_default)  %>%
  mutate(
    fpr = round((1 - specificity), 2),
    tpr = round(sensitivity, 3),
    score_threshold =  round(.threshold, 3)
  ) %>%
  group_by(fpr) %>%
  summarise(threshold = round(mean(score_threshold),3),
            tpr = mean(tpr)) %>%
  filter(fpr <= 0.1)
}

predict_and_operate_nn(nn_workflow_tuned)
```
#nn operating
```{r}
predict_and_opnn <- function(workflow_fit){
  scored_train <- predict(workflow_fit, nn_train, type="prob") %>%
    bind_cols(predict(workflow_fit, nn_train, type="class")) %>% 
     mutate(part = 'train', .pred_class = as.factor(if_else(.pred_default >=.407,'default','current'))) %>% 
    bind_cols(.,nn_train) 

scored_test <- predict(workflow_fit, nn_test, type="prob") %>%
   bind_cols(predict(workflow_fit, nn_test, type="class")) %>%
  mutate(part = 'test', .pred_class = as.factor(if_else(.pred_default >=.407,'default','current'))) %>% 
    bind_cols(.,nn_test)

#Metrics: Train and Test 
  auc<- scored_train %>% 
    metrics(truth = loan_status, 
            predicted = .pred_default, 
            estimate = .pred_class) %>%
    mutate(part="training") %>%
    bind_rows( scored_test %>% 
                  metrics(truth = loan_status, 
            predicted = .pred_default, 
            estimate = .pred_class) %>%
                 mutate(part="testing") ) %>%
    filter(.metric %in% c('accuracy','mn_log_loss','roc_auc')) %>%
    pivot_wider(names_from = .metric, values_from=.estimate) 
  
  print(auc)
  
 roc_chart <- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  roc_curve(truth=loan_status, predicted=.pred_default) %>% 
  autoplot() +
  geom_vline(xintercept = 0.04,    
             color = "red",
             linetype = "longdash") +
   geom_vline(xintercept = 0.20,    
             color = "black",
             linetype = "longdash") +
   labs(title = 'ROC For Logistic Regression', x = "FPR(1 - specificity)", y = "TPR(recall)") 
 
 print(roc_chart)
  
 con_train <-  scored_train %>%
  conf_mat(
  truth = loan_status,
  estimate = .pred_class,
  dnn = c("Prediction", "Truth")
) %>%
  autoplot(type = "heatmap") + 
  labs(title="Training Confusion Matrix")
 
 print(con_train)

 con_test <-  scored_test %>%
  conf_mat(
  truth = loan_status,
  estimate = .pred_class,
  dnn = c("Prediction", "Truth")
) %>%
  autoplot(type = "heatmap") + 
  labs(title="Testing Confusion Matrix")
  
   print(con_test)
   
    precision<- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  precision(loan_status, .pred_class) 
      
    
    print(precision)
    
recall <-bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  recall(loan_status, .pred_class) 

print(recall)

f1<- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  f_meas(loan_status, .pred_class) 

print(f1)

 score_dist <-scored_test %>%
  ggplot(aes(.pred_default,fill=loan_status)) +
  geom_histogram(bins=50) +
  geom_vline(aes(xintercept=.407, color="blue")) +
  labs(title = 'Neural Networks', subtitle = "Operating @.404 Threshold") 

print(score_dist)



}

predict_and_opnn(nn_workflow_tuned)
```
#NN global
```{r}
 nn_explainer<- explain_tidymodels(
  nn_workflow_tuned,
  data = nn_train ,
  y = train$loan_default ,
  verbose = TRUE

)

nn_scored_test <- bind_cols(
  predict(nn_workflow_tuned,nn_test, type="prob"), 
   predict(nn_workflow_tuned,nn_test, type="class"),
  nn_test) %>% 
  mutate(part = "test") 

nn_single_record <- nn_scored_test %>% 
  dplyr::select(model_variables) %>%
  mutate(intercept = "", prediction = .pred_default) %>%
  slice_max(order_by = .pred_default, n=10) %>% head(1) 

nn_breakdown <- predict_parts(explainer = nn_explainer, 
                               new_observation = nn_single_record 
                               )

nn_breakdown %>% plot()

nn_breakdown %>%
  as_tibble() -> breakdown_data_nn

nn_single_record %>% 
 gather(key="variable_name",value="value") -> prediction_data_nn

#


#step 4c. predict a probabilty for a plot
prediction_prob1 <- nn_single_record[,".pred_default"] %>% pull()

breakdown_data_nn %>% 
  inner_join(prediction_data_nn) %>%
  mutate(contribution = round(contribution,3),) %>%
  filter(variable_name != "intercept", contribution >0) %>%
  mutate(variable = paste(variable_name,value,sep = ": ")) %>% 
  ggplot(aes(y=reorder(variable_name, contribution), x= contribution, fill=sign)) +
  geom_col() + 
  geom_text(aes(label=contribution), 
          size=4,
            position=position_dodge(width=0.7),
            vjust=0.5,
            )+
  labs(
    title = "DALEX Neural Network Explainations",
    subtitle = paste("Feature Importance | Predicted:",as.character(round(prediction_prob1,3))),
                    x="Contribution",
                    y="Features")

```


#XGBoost prepping data
```{r}
#XGBoost
xgb_prep <- loan %>% 
  mutate(loan_status = as.factor(loan_status))


set.seed(2131)
xgb_split <- initial_split(xgb_prep, prop = 0.75)
xgb_train <- training(xgb_split) 
xgb_test  <-  testing(xgb_split)
```
#XGB Recipe
```{r}
xgb_recipe <- recipe(loan_status ~. , data = nn_train) %>%
  step_rm(emp_title, url, desc, title, zip_code, earliest_cr_line, revol_util, last_pymnt_d, member_id, id, addr_state, next_pymnt_d,  application_type,  issue_d, collections_12_mths_ex_med, policy_code, chargeoff_within_12_mths,delinq_2yrs, mths_since_last_delinq, 	mths_since_last_record, pub_rec_bankruptcies, sub_grade,dti, funded_amnt_inv, acc_now_delinq, tax_liens, emp_length, home_ownership, verification_status, purpose, delinq_amnt,out_prncp_inv, fico_range_high, total_acc)  %>% 
  step_impute_median(all_numeric_predictors()) %>% # missing values numeric 
  step_novel(all_nominal_predictors()) %>% # new factor levels 
  step_unknown(all_nominal_predictors()) %>%# missing values 
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
  step_nzv(all_predictors()) #Unneccesary, but if there is a variable that provides limited variablity then it removes it
  
  

bake(xgb_recipe %>% prep(),xgb_train %>% sample_n(1000))
```

#XGB K-fold
```{r}
xgb_kfold_splits <- vfold_cv(xgb_train, v=5)
```

#XGB Define Model
```{r}
xgb_model <- boost_tree(trees=tune(), 
                        learn_rate = tune(),
                        tree_depth = tune()) %>%
  set_engine("xgboost",
             importance="impurity") %>%
  set_mode("classification")

xgb_wflow <-workflow() %>%
  add_recipe(xgb_recipe) %>%
  add_model(xgb_model)
```

#XGB Tuning
```{r}
xgb_search_res <- xgb_wflow %>% 
  tune_bayes(
    resamples = xgb_kfold_splits,
    # Generate five at semi-random to start
    initial = 15,
    iter = 50, 
    # How to measure performance?
    metrics = metric_set(roc_auc),
    control = control_bayes(no_improve = 5, verbose = TRUE)
  )
```


#XGB Final Fit
```{r}
#Best Find
highest_xgb_roc <- xgb_search_res %>%
  select_best("roc_auc")

xgb_wflow <- finalize_workflow(
  xgb_wflow, highest_xgb_roc
) %>% 
  fit(xgb_train)

#Function: Predicts, Evaluates AUC, Accuracy, Log loss Precision, Recall, F1,  Confusion Matrix, VIP 
eval_xgb <- function(workflow_fit){
  # 1. Make Predictions
scored_train <- predict(workflow_fit, xgb_train, type="prob") %>%
      mutate(part = 'train') %>% 
    bind_cols(predict(workflow_fit, xgb_train, type="class")) %>%
    bind_cols(.,xgb_train) 

scored_test <- predict(workflow_fit, xgb_test, type="prob") %>%
  mutate(part = 'test') %>% 
    bind_cols(predict(workflow_fit, xgb_test, type="class")) %>%
    bind_cols(.,xgb_test)



 auc<- scored_train %>% 
    metrics(truth = loan_status, 
            predicted = .pred_default, 
            estimate = .pred_class) %>%
    mutate(part="training") %>%
    bind_rows( scored_test %>% 
                  metrics(truth = loan_status, 
            predicted = .pred_default, 
            estimate = .pred_class) %>%
                 mutate(part="testing") ) %>%
    filter(.metric %in% c('accuracy','mn_log_loss','roc_auc')) %>%
    pivot_wider(names_from = .metric, values_from=.estimate) 
  
  print(auc)
  
    
 roc_chart <- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  roc_curve(truth=loan_status, predicted=.pred_default) %>% 
  autoplot() +
  geom_vline(xintercept = 0.25,    
             color = "red",
             linetype = "longdash") +
   geom_vline(xintercept = 0.5,    
             color = "black",
             linetype = "longdash") +
   labs(title = 'ROC For XGBoost Regression', x = "FPR(1 - specificity)", y = "TPR(recall)", subtitle = "ROC With a Selected Threshold") 
 
 print(roc_chart)
  
 con_train <-  scored_train %>%
  conf_mat(
  truth = loan_status,
  estimate = .pred_class,
  dnn = c("Prediction", "Truth")
) %>%
  autoplot(type = "heatmap") + 
  labs(title="Training Confusion Matrix")
 
 print(con_train)

 con_test <-  scored_test %>%
  conf_mat(
  truth = loan_status,
  estimate = .pred_class,
  dnn = c("Prediction", "Truth")
) %>%
  autoplot(type = "heatmap") + 
  labs(title="Testing Confusion Matrix")
  
   print(con_test)
   
    precision<- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  precision(loan_status, .pred_class) 
      
    
    print(precision)
    
recall <-bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  recall(loan_status, .pred_class) 

print(recall)

f1<- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  f_meas(loan_status, .pred_class) 

print(f1)

vip <-workflow_fit %>%
  extract_fit_parsnip() %>%
  vi()

print(vip)


 score_dist <-scored_test %>%
  ggplot(aes(.pred_default,fill=loan_status)) +
  geom_histogram(bins=50) +
  geom_vline(aes(xintercept=.254, color="red")) +
  geom_vline(aes(xintercept=.5, color="green")) +
  geom_vline(aes(xintercept=.75, color="blue")) +
  labs(title = 'XGBoost Precision Recall Threshold', 
       subtitle = "XGBoost Histogram of Predicted Defaults") 

print(score_dist)
}

eval_xgb(xgb_wflow)


```
#XGB Operating 
```{r}
predict_and_operate_xgb <- function(workflow_fit){
  scored_train <- predict(workflow_fit, xgb_train, type="prob") %>%
    bind_cols(predict(workflow_fit, xgb_train, type="class")) %>%
    bind_cols(.,xgb_train) 
  
  scored_test <- predict(workflow_fit, xgb_test, type="prob") %>%
    bind_cols(predict(workflow_fit, xgb_test, type="class")) %>%
    bind_cols(.,xgb_test)

scored_test %>%
  roc_curve(loan_status, .pred_default)  %>%
  mutate(
    fpr = round((1 - specificity), 2),
    tpr = round(sensitivity, 3),
    score_threshold =  round(.threshold, 3)
  ) %>%
  group_by(fpr) %>%
  summarise(threshold = round(mean(score_threshold),3),
            tpr = mean(tpr)) %>%
  filter(fpr <= 0.1)
}

predict_and_operate_xgb(xgb_wflow)
```

#XGB Predit @ operating range 
```{r}
predict_and_xgop <- function(workflow_fit){
  scored_train <- predict(workflow_fit, xgb_train, type="prob") %>%
    bind_cols(predict(workflow_fit, xgb_train, type="class")) %>% 
     mutate(part = 'train', .pred_class = as.factor(if_else(.pred_default >=.330,'default','current'))) %>% 
    bind_cols(.,xgb_train) 

scored_test <- predict(workflow_fit, xgb_test, type="prob") %>%
   bind_cols(predict(workflow_fit, xgb_test, type="class")) %>%
  mutate(part = 'test', .pred_class = as.factor(if_else(.pred_default >=.330,'default','current'))) %>% 
    bind_cols(.,xgb_test)

#Metrics: Train and Test 
  auc<- scored_train %>% 
    metrics(truth = loan_status, 
            predicted = .pred_default, 
            estimate = .pred_class) %>%
    mutate(part="training") %>%
    bind_rows( scored_test %>% 
                  metrics(truth = loan_status, 
            predicted = .pred_default, 
            estimate = .pred_class) %>%
                 mutate(part="testing") ) %>%
    filter(.metric %in% c('accuracy','mn_log_loss','roc_auc')) %>%
    pivot_wider(names_from = .metric, values_from=.estimate) 
  
  print(auc)
  
 roc_chart <- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  roc_curve(truth=loan_status, predicted=.pred_default) %>% 
  autoplot() +
  geom_vline(xintercept = 0.04,    
             color = "red",
             linetype = "longdash") +
   geom_vline(xintercept = 0.20,    
             color = "black",
             linetype = "longdash") +
   labs(title = 'ROC For Logistic Regression', x = "FPR(1 - specificity)", y = "TPR(recall)") 
 
 print(roc_chart)
  
 con_train <-  scored_train %>%
  conf_mat(
  truth = loan_status,
  estimate = .pred_class,
  dnn = c("Prediction", "Truth")
) %>%
  autoplot(type = "heatmap") + 
  labs(title="Training Confusion Matrix")
 
 print(con_train)

 con_test <-  scored_test %>%
  conf_mat(
  truth = loan_status,
  estimate = .pred_class,
  dnn = c("Prediction", "Truth")
) %>%
  autoplot(type = "heatmap") + 
  labs(title="Testing Confusion Matrix")
  
   print(con_test)
   
    precision<- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  precision(loan_status, .pred_class) 
      
    
    print(precision)
    
recall <-bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  recall(loan_status, .pred_class) 

print(recall)

f1<- bind_rows(scored_train, scored_test) %>%
  group_by(part) %>%
  f_meas(loan_status, .pred_class) 

print(f1)

 score_dist <-scored_test %>%
  ggplot(aes(.pred_default,fill=loan_status)) +
  geom_histogram(bins=50) +
  geom_vline(aes(xintercept=.330, color="green")) +
  labs(title = 'XGBoost Precision Recaall Threshold', subtitle = "Histogram of .pred_default @ .330 ") 

print(score_dist)

}

predict_and_xgop(xgb_wflow)
```



#Global Explanation of Best Model XGBoost
```{r}
#Create explainer
xgb_model_explainer <- 
  explain_tidymodels(
    xgb_wflow,   # fitted workflow object 
    data = xgb_train,    # original training data
    y = train$loan_status, # predicted outcome 
    label = "xgboost",
    verbose = FALSE
  )
```


```{r}
xgb_scored_test <- bind_cols(
  predict(xgb_wflow,xgb_test, type="prob"), 
   predict(xgb_wflow,xgb_test, type="class"),
  xgb_test) %>% 
  mutate(part = "test") 

# lowest scores 
xgb_scored_test %>%
  slice_min(order_by = .pred_default, n=10)

# highest scores 
xgb_scored_test %>%
  slice_max(order_by = .pred_default, n=10)

# highest scores good loans
xgb_scored_test %>%
  filter(loan_status == "default") %>%
  slice_max(order_by = .pred_default, n=10)
```
```{r}
#Step 2

model_variables = c(".pred_default","loan_status", 
                    "loan_amnt" ,
                      "funded_amnt" ,  
                      "grade" , 
                      "sub_grade" , 
                      "annual_inc" , 
                      "fico_range_low", 'id', 'member_id', 'funded_amnt_inv', 'term', 'int_rate', 'installment', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'pymnt_plan', 'url', 'desc', 'purpose', 'title', 'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line', 'fico_range_high', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'out_prncp', 'out_prncp_inv', 'total_rec_late_fee', 'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d', 'collections_12_mths_ex_med', 'policy_code', 'application_type', 'acc_now_delinq', 'chargeoff_within_12_mths', 'delinq_amnt', 'pub_rec_bankruptcies', 'tax_liens' )



single_record <- xgb_scored_test %>% 
  dplyr::select(model_variables) %>%
  mutate(intercept = "", prediction = .pred_default) %>%
  slice_max(order_by = .pred_default, n=10) %>% head(1) 

#Step 3. run the explainer 
xgb_breakdown <- predict_parts(explainer = xgb_model_explainer, 
                               new_observation = single_record 
                               )

#Plot 
xgb_breakdown %>% plot()

xgb_breakdown %>%
  as_tibble() -> breakdown_data 

single_record %>% 
 gather(key="variable_name",value="value") -> prediction_data 

#step 4c. predict a probabilty for a plot
prediction_prob <- single_record[,".pred_default"] %>% pull()

breakdown_data %>% 
  inner_join(prediction_data) %>%
  mutate(contribution = round(contribution,3),) %>%
  filter(variable_name != "intercept", contribution >0) %>%
  mutate(variable = paste(variable_name,value,sep = ": ")) %>% 
  ggplot(aes(y=reorder(variable_name, contribution), x= contribution, fill=sign)) +
  geom_col() + 
  geom_text(aes(label=contribution), 
          size=4,
            position=position_dodge(width=0.7),
            vjust=0.5,
            )+
  labs(
    title = "DALEX XGBoost Explainations",
    subtitle = paste("Feature Importance | Predicted:",as.character(round(prediction_prob,3))),
                    x="Contribution",
                    y="Features")
```

```{r}
#Partial Dependency Plot
#Create explainer: ###last_pymnt_amnt### 

#Create profile for single variable 
profile_last_credit_pull_d <- model_profile(
  xgb_model_explainer,
  variables = c("last_credit_pull_d")
)

#Plotting
as_tibble(profile_last_credit_pull_d$agr_profiles) %>%
  mutate(profile_last_credit_pull_d = `_x_`,
         avg_prediction_impact = `_yhat_`)  %>% 
  ggplot(aes(x=profile_last_credit_pull_d, y=avg_prediction_impact)) +
  geom_point()  + 
  labs(
    x = "Variable: Last Credit Pull_D",
     y = " Average prediction Impact ",
    color = NULL,
    title = "Partial dependence plot Last Credit Pull",
    subtitle = "How does Last Credit Pull impact predictions (on average)"
  ) 

#Profile 2
profile_last_pymnt_amnt <- model_profile(
  xgb_model_explainer,
  variables = c("last_pymnt_amnt")
)


as_tibble(profile_last_pymnt_amnt$agr_profiles) %>%
  mutate(profile_last_pymnt_amnt = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_last_pymnt_amnt, y=avg_prediction_impact)) + geom_smooth() + geom_point(aes(fill = profile_last_pymnt_amnt))+ theme_economist() + theme(legend.position="false", strip.background = element_blank(), strip.text.x = element_blank()) +
  labs(
    x = "Variable: Last Payment Amount",
     y = " Average Prediction Impact ",
    color = NULL,
    title = "XGB: Partial dependence plot LPA",
    subtitle = "How does Last Payment Amount Impact Predictions (on average)"
  ) 

#Profile 3
profile_int_rate <- model_profile(
  xgb_model_explainer,
  variables = c("int_rate")
)

#Plotting 3

as_tibble(profile_int_rate$agr_profiles) %>%
  mutate(profile_int_rate = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_int_rate, y=avg_prediction_impact)) + geom_smooth() + geom_point(aes(fill = profile_int_rate))+ theme_economist() + theme(legend.position="false", strip.background = element_blank(), strip.text.x = element_blank()) +
  labs(
    x = "Variable: Interest Rate",
     y = " Average Prediction Impact ",
    color = NULL,
    title = "XGB:Partial Dependence plot Interest Rate ",
    subtitle = "How does Interest Rate Impact Predictions (on average)"
  ) 

#Profile 4
profile_loan_amnt <- model_profile(
  xgb_model_explainer,
  variables = c("loan_amnt")
)

#plotting
as_tibble(profile_loan_amnt$agr_profiles) %>%
  mutate(profile_loan_amnt = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_loan_amnt, y=avg_prediction_impact)) + geom_smooth() + geom_point(aes(fill = profile_loan_amnt))+ theme_economist() + theme(legend.position="false", strip.background = element_blank(), strip.text.x = element_blank()) +
  labs(
    x = "Variable: Loan Amount",
     y = " Average Prediction Impact ",
    color = NULL,
    title = "XGB:Partial Dependence plot Loan Amount ",
    subtitle = "How does Loan Amount Impact Predictions (on average)"
  ) 


#Profile 5
profile_funded_amnt <- model_profile(
  xgb_model_explainer,
  variables = c("funded_amnt")
)

#plotting
as_tibble(profile_funded_amnt$agr_profiles) %>%
  mutate(profile_funded_amnt = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_funded_amnt, y=avg_prediction_impact)) + geom_smooth() + geom_point(aes(fill = profile_funded_amnt))+ theme_economist() + theme(legend.position="false", strip.background = element_blank(), strip.text.x = element_blank()) +
  labs(
    x = "Variable:  Funded Amount",
     y = " Average Prediction Impact ",
    color = NULL,
    title = "XGB:Partial Dependence Plot of Funded Amount ",
    subtitle = "How does  Funded Amount Impact Predictions (on average)"
  ) 







```



#Local Explanation 
```{r}
# step 3. run the explainer 
xgb_shapley <- predict_parts(explainer = xgb_model_explainer, 
                               new_observation = single_record,
                               type="shap")
#plot
xgb_shapley %>% plot()

xgb_shapley %>%
  as_tibble() -> shap_data 

single_record %>% 
 gather(key="variable_name",value="value") -> prediction_data

# step 4c. get a predicted probability for plot 
prediction_prob <- single_record[,".pred_default"] %>% mutate(.pred_default = round(.pred_default,3)) %>% pull() 

#plot it
shap_data %>% 
  inner_join(prediction_data) %>%
  group_by(variable_name) %>%
  summarize(contribution = mean(contribution)) %>%
  mutate(contribution = round(contribution,3),
         sign = if_else(contribution < 0, "neg","pos")) %>%
  ggplot(aes(y=reorder(variable_name, contribution), x= contribution, fill=sign)) +
  geom_col() + 
  geom_text(aes(label=contribution))+
  labs(
    title = "SHAPLEY explainations",
    subtitle = paste("predicted probablity = ",prediction_prob) ,
                    x="contribution",
                    y="features")



```
Function 
```{r}
loan_sample <- xgb_train %>% sample_n(1000)
loans_explainer <- explain_tidymodels(
    xgb_wflow,   # fitted workflow object 
    data = loan_sample,    # original training data
    y = loan_sample$loan_status, # predicted outcome 
    label = "xgboost",
    verbose = FALSE
  )

explain_prediction <- function(single_record){
  # step 3. run the explainer 
record_shap <- predict_parts(explainer = xgb_model_explainer, 
                               new_observation = single_record,
                               #type="fastshap"
                             )

# step 4. plot it. 
# you notice you don't get categorical values ...  
record_shap %>% plot() 

# --- more involved explanations with categories. ---- 

# step 4a.. convert breakdown to a tibble so we can join it
record_shap %>%
  as_tibble() -> shap_data 

# step 4b. transpose your single record prediction 
single_record %>% 
 gather(key="variable_name",value="value") -> prediction_data 

# step 4c. get a predicted probability for plot 
prediction_prob <- single_record[,".pred_default"] %>% mutate(.pred_default = round(.pred_default,3)) %>% pull() 

# step 5. plot it.
shap_data %>% 
  inner_join(prediction_data) %>%
  mutate(variable = paste(variable_name,value,sep = ": ")) %>% 
  group_by(variable) %>%
  summarize(contribution = mean(contribution)) %>%
  mutate(contribution = round(contribution,3),
         sign = if_else(contribution < 0, "neg","pos")) %>%
  ggplot(aes(y=reorder(variable, contribution), x= contribution, fill=sign)) +
  geom_col() + 
  geom_text(aes(label=contribution))+
  labs(
    title = "SHAPLEY explainations",
    subtitle = paste("predicted probablity = ",prediction_prob) ,
                    x="contribution",
                    y="features")
  
}

explain_prediction(top_10_tp)

top_10_tp <- xgb_scored_test %>%
  filter(.pred_class == loan_status) %>%
  filter(loan_status == "default") %>%
  slice_max(.pred_default,n=10)

top_10_fp <-xgb_scored_test %>%
  filter(.pred_class != loan_status) %>%
  filter(loan_status == "current") %>%
  slice_max(.pred_default,n=10)

top_10_fn <- xgb_scored_test %>%
  filter(.pred_class != loan_status ) %>%
  filter(loan_status == "default") %>%
  slice_max(.pred_default,n=10)

summary(loan)

```

```{r}
#predicting on holdout 
bind_cols(predict(xgb_wflow, holdout), holdout) %>% 
  dplyr::select(id,loan_status = .pred_default) %>% 
  write_csv("kaggle.csv")

predict(xgb_wflow, holdout, type = "prob")  %>%
  bind_cols(holdout) %>%
  select(id,loan_status = .pred_default) %>% write_csv("final_kag.csv")
```

